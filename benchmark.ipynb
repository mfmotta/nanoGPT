{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import config.train_shakespeare_char as params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mm-motta\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nanoGPT/wandb/run-20231012_145938-irihy9dw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/m-motta/profile-attention-nano-gpt/runs/irihy9dw' target=\"_blank\">flash-n_iters400-n_head6-h_size384-seq_len256</a></strong> to <a href='https://wandb.ai/m-motta/profile-attention-nano-gpt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/m-motta/profile-attention-nano-gpt' target=\"_blank\">https://wandb.ai/m-motta/profile-attention-nano-gpt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/m-motta/profile-attention-nano-gpt/runs/irihy9dw' target=\"_blank\">https://wandb.ai/m-motta/profile-attention-nano-gpt/runs/irihy9dw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'backend': 'nccl', 'device': 'cuda', 'dtype': 'bfloat16', 'compile': True}\n",
    "wandb.init(project=params.wandb_project, name=params.wandb_run_name, config=config, sync_tensorboard=True)\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'skip_first': 5, 'wait': 5, 'warmup': 5, 'active': 3, 'repeat': 2}\n"
     ]
    }
   ],
   "source": [
    "# Profiling with PyTorch\n",
    "\n",
    "#We will first perform a sanity check and see whether profiling with different number of iterations leads to different results.\n",
    "\n",
    "\n",
    "fixed_params = dict(n_layer = params.n_layer, \n",
    "                    n_head = params.n_head, \n",
    "                    n_embd = params.n_embd, \n",
    "                    block_size = params.block_size,\n",
    "                    bias = params.bias, \n",
    "                    dropout = params.dropout) \n",
    "\n",
    "varying_params = dict(max_iters = [400, 4000, 5000], test=[11, 22],\n",
    "                      flash = [True, False])\n",
    "\n",
    "profiling_params = params.profiler_schedule_args\n",
    "\n",
    "print(profiling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['max_iters', 'flash'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_dict(varying_params):\n",
    "    keys = list(varying_params.keys())\n",
    "    lists = list(varying_params.values())\n",
    "\n",
    "    def recursive_loop(level, loop_args):\n",
    "        if level == len(keys):\n",
    "            \n",
    "        else:\n",
    "            for item in lists[level]:\n",
    "                recursive_loop(level + 1, loop_args + (item,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([[400, 4000], [True, False]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 varying_params.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nanoGPT/benchmark.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726f6a65637473227d/home/nanoGPT/benchmark.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     run \u001b[39m=\u001b[39m defaultdict\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726f6a65637473227d/home/nanoGPT/benchmark.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m values:\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726f6a65637473227d/home/nanoGPT/benchmark.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m         run[key]\u001b[39m=\u001b[39mv\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726f6a65637473227d/home/nanoGPT/benchmark.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     runs\u001b[39m.\u001b[39mappend(run)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726f6a65637473227d/home/nanoGPT/benchmark.ipynb#X63sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m runs\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "runs = []\n",
    "run = defaultdict\n",
    "for (key, values) in varying_params.items():\n",
    "    run[key]\n",
    "    for v in values:\n",
    "        run[key]=v\n",
    "    runs.append(run)\n",
    "\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('max_iters', 400), ('max_iters', 4000), ('flash', True), ('flash', False)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = []\n",
    "run = {}\n",
    "[runs.append(run[key]=v) for (key, values) in varying_params.items() for v in values] for i range(2) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_iters': 400}, {'max_iters': 4000}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = []\n",
    "key = 'max_iters'\n",
    "for v in varying_params[key]:\n",
    "    run = {}\n",
    "    run[key] = v\n",
    "    runs.append(run)\n",
    "\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values_positions {0: 400, 1: True, 2: 11}\n",
      "values_positions {0: 400, 1: True, 2: 22}\n",
      "values_positions {0: 400, 1: False, 2: 11}\n",
      "values_positions {0: 400, 1: False, 2: 22}\n",
      "values_positions {0: 4000, 1: True, 2: 11}\n",
      "values_positions {0: 4000, 1: True, 2: 22}\n",
      "values_positions {0: 4000, 1: False, 2: 11}\n",
      "values_positions {0: 4000, 1: False, 2: 22}\n",
      "values_positions {0: 5000, 1: True, 2: 11}\n",
      "values_positions {0: 5000, 1: True, 2: 22}\n",
      "values_positions {0: 5000, 1: False, 2: 11}\n",
      "values_positions {0: 5000, 1: False, 2: 22}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'max_iters': 400, 'flash': True, 'test': 11},\n",
       " {'max_iters': 400, 'flash': True, 'test': 22},\n",
       " {'max_iters': 400, 'flash': False, 'test': 11},\n",
       " {'max_iters': 400, 'flash': False, 'test': 22},\n",
       " {'max_iters': 4000, 'flash': True, 'test': 11},\n",
       " {'max_iters': 4000, 'flash': True, 'test': 22},\n",
       " {'max_iters': 4000, 'flash': False, 'test': 11},\n",
       " {'max_iters': 4000, 'flash': False, 'test': 22},\n",
       " {'max_iters': 5000, 'flash': True, 'test': 11},\n",
       " {'max_iters': 5000, 'flash': True, 'test': 22},\n",
       " {'max_iters': 5000, 'flash': False, 'test': 11},\n",
       " {'max_iters': 5000, 'flash': False, 'test': 22}]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = []\n",
    "keys = ['max_iters', 'flash','test']\n",
    "n=0\n",
    "values_positions = {} #{position:values} values corresponding to keys in position n in the dictionary\n",
    "\n",
    "for v0 in varying_params[keys[n]]:\n",
    "    values_positions[n]=v0\n",
    "    n+=1\n",
    "\n",
    "    for v1 in varying_params[keys[n]]:\n",
    "        values_positions[n]=v1\n",
    "        n+=1\n",
    "\n",
    "        for v2 in varying_params[keys[n]]:\n",
    "            values_positions[n]=v2\n",
    "            n+=1\n",
    "\n",
    "            run = {}\n",
    "            print('values_positions',values_positions)\n",
    "            for (pos, v) in values_positions.items():\n",
    "                run[keys[pos]] = v\n",
    "\n",
    "            n-=1\n",
    "            runs.append(run)\n",
    "        \n",
    "\n",
    "        n-=1\n",
    "    values_positions = {}\n",
    "\n",
    "    n=0\n",
    "    \n",
    "    \n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_iters': 400, 'flash': True},\n",
       " {'max_iters': 400, 'flash': False},\n",
       " {'max_iters': 4000, 'flash': True},\n",
       " {'max_iters': 4000, 'flash': False},\n",
       " {'max_iters': 5000, 'flash': True},\n",
       " {'max_iters': 5000, 'flash': False}]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = []\n",
    "keys = ['max_iters', 'flash']\n",
    "n=0\n",
    "values_positions = {} #values of keys in position n in the dictionary\n",
    "\n",
    "for v0 in varying_params[keys[n]]:\n",
    "    values_positions[v0]=n\n",
    "    n+=1\n",
    "\n",
    "    for v1 in varying_params[keys[n]]:\n",
    "        values_positions[v1]=n\n",
    "        n+=1\n",
    "\n",
    "        run = {}\n",
    "        for (v,pos) in values_positions.items():\n",
    "            run[keys[pos]] = v\n",
    "\n",
    "        n=1\n",
    "        runs.append(run)\n",
    "\n",
    "    n=0\n",
    "    values_positions = {}\n",
    "    \n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_iters': 400, 'flash': True},\n",
       " {'max_iters': 400, 'flash': False},\n",
       " {'max_iters': 4000, 'flash': True},\n",
       " {'max_iters': 4000, 'flash': False}]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = []\n",
    "keys = ['max_iters', 'flash']\n",
    "n=0\n",
    "values_positions = {} #values of keys in position n in the dictionary\n",
    "for v0 in varying_params[keys[n]]:\n",
    "    values_positions[v0]=n\n",
    "    n+=1\n",
    "    for v1 in varying_params[keys[n]]:\n",
    "        values_positions[v1]=n\n",
    "        run = {}\n",
    "        for (v,pos) in values_positions.items():\n",
    "            run[keys[pos]] = v\n",
    "        runs.append(run)\n",
    "\n",
    "    n=0\n",
    "    values_positions = {}\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_iters': 400, 'flash': True},\n",
       " {'max_iters': 400, 'flash': False},\n",
       " {'max_iters': 4000, 'flash': True},\n",
       " {'max_iters': 4000, 'flash': False}]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = []\n",
    "key = 'max_iters'\n",
    "for v in varying_params[key]:\n",
    "    key = 'flash'\n",
    "    for w in varying_params[key]:\n",
    "        run = {}\n",
    "        run['max_iters'] = v\n",
    "        run['flash'] = w\n",
    "        runs.append(run)\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iters 0 [400, 4000]\n",
      "max_iters 1 [400, 4000]\n",
      "max_iters 0 [True, False]\n",
      "max_iters 1 [True, False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_iters': False}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_dict(my_dict):\n",
    "    keys = my_dict.keys()\n",
    "    n = 0\n",
    "    runs = {}\n",
    "\n",
    "    def nested_loop(n, runs, keys, values):\n",
    "        if n == len(values):\n",
    "            return runs\n",
    "        else:\n",
    "            for k in keys:\n",
    "                print(k, n, values)\n",
    "                runs[k] = values[n]\n",
    "                return nested_loop(n+1, runs, keys, values)\n",
    "            \n",
    "    for key in keys:\n",
    "        values = list(my_dict[key])\n",
    "        nested_loop(n, runs, keys, values)\n",
    "\n",
    "    \n",
    "    return runs\n",
    "\n",
    "expand_dict(varying_params)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n 2\n",
      "run[key] [400, 4000]\n",
      "value of max_iters : 400\n",
      "return dict {'max_iters': 400}\n",
      "n 1\n",
      "run[key] [400, 4000]\n",
      "value of max_iters : 400\n",
      "return dict {'max_iters': 400}\n",
      "0 {'max_iters': 400}\n",
      "value of max_iters : 4000\n",
      "return dict {'max_iters': 4000}\n",
      "0 {'max_iters': 4000}\n",
      "value of max_iters : 4000\n",
      "return dict {'max_iters': 4000}\n",
      "n 1\n",
      "run[key] [400, 4000]\n",
      "value of max_iters : 400\n",
      "return dict {'max_iters': 400}\n",
      "0 {'max_iters': 400}\n",
      "value of max_iters : 4000\n",
      "return dict {'max_iters': 4000}\n",
      "0 {'max_iters': 4000}\n",
      "n 2\n",
      "run[key] [True, False]\n",
      "value of flash : True\n",
      "return dict {'max_iters': 4000, 'flash': True}\n",
      "n 1\n",
      "run[key] [True, False]\n",
      "value of flash : True\n",
      "return dict {'max_iters': 4000, 'flash': True}\n",
      "0 {'max_iters': 4000, 'flash': True}\n",
      "value of flash : False\n",
      "return dict {'max_iters': 4000, 'flash': False}\n",
      "0 {'max_iters': 4000, 'flash': False}\n",
      "value of flash : False\n",
      "return dict {'max_iters': 4000, 'flash': False}\n",
      "n 1\n",
      "run[key] [True, False]\n",
      "value of flash : True\n",
      "return dict {'max_iters': 4000, 'flash': True}\n",
      "0 {'max_iters': 4000, 'flash': True}\n",
      "value of flash : False\n",
      "return dict {'max_iters': 4000, 'flash': False}\n",
      "0 {'max_iters': 4000, 'flash': False}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'max_iters': 4000, 'flash': False}, {'max_iters': 4000, 'flash': False}]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "varying_params = dict(max_iters = [400, 4000], \n",
    "                      flash = [True, False])\n",
    "\n",
    "def nested_loop(n, run, key):\n",
    "    if n==0:\n",
    "        print('0', run)\n",
    "        return run\n",
    "    \n",
    "    print('n',n)\n",
    "    print('run[key]',varying_params[key])\n",
    "    for v in varying_params[key]:\n",
    "        print('value of', key, ':', v)\n",
    "        run[key] = v\n",
    "        \n",
    "        print('return dict', run)\n",
    "        nested_loop(n-1, run, key)\n",
    "    return run\n",
    "\n",
    "runs = []\n",
    "run={}\n",
    "for k in varying_params.keys():\n",
    "    lrun = nested_loop(2, run, k)\n",
    "    runs.append(lrun)\n",
    "\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_iters': 400}, {'max_iters': 4000}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = []\n",
    "for v in varying_params['varying_params']:\n",
    "    run = {}\n",
    "    run['max_iters'] = v\n",
    "    \n",
    "    runs.append(run)\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_iters': 400, 'flash': True},\n",
       " {'max_iters': 400, 'flash': False},\n",
       " {'max_iters': 4000, 'flash': True},\n",
       " {'max_iters': 4000, 'flash': False},\n",
       " {'max_iters': 20000, 'flash': True},\n",
       " {'max_iters': 20000, 'flash': False}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = []\n",
    "for v in varying_params['max_iters']:\n",
    "    for w in [True, False]:\n",
    "        run = {}\n",
    "        run['max_iters'] = v\n",
    "        run['flash'] = w\n",
    "        runs.append(run)\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nanoGPT/benchmark.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726f6a65637473227d/home/nanoGPT/benchmark.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m\u001b[39m*\u001b[39m([keys, values]):\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726f6a65637473227d/home/nanoGPT/benchmark.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39mprint\u001b[39m(k,v)\n\u001b[0;32m---> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726f6a65637473227d/home/nanoGPT/benchmark.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m run_experiments(fixed_params, varying_params)\n",
      "\u001b[1;32m/home/nanoGPT/benchmark.ipynb Cell 5\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726f6a65637473227d/home/nanoGPT/benchmark.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(varying_params\u001b[39m.\u001b[39mvalues())\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726f6a65637473227d/home/nanoGPT/benchmark.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(varying_params\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726f6a65637473227d/home/nanoGPT/benchmark.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39;49m\u001b[39m*\u001b[39;49m([keys, values]):\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f70726f6a65637473227d/home/nanoGPT/benchmark.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(k,v)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'type'"
     ]
    }
   ],
   "source": [
    "def run_experiments(fixed_params, varying_params):\n",
    "    runs = defaualtdict()\n",
    "\n",
    "\n",
    "    #tuple()\n",
    "    values = list(varying_params.values())\n",
    "    keys = list(varying_params.keys())\n",
    "    for k, v in zip*([keys, values]):\n",
    "        print(k,v)\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "            \n",
    "        \n",
    "            \n",
    "run_experiments(fixed_params, varying_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run experiments:\n",
    "\n",
    "vary:\n",
    "\n",
    "n_iters  - to check if profiling changes with more or less iterations --it should not\n",
    "\n",
    "        for (n_heads*h_size = embedding dimensionality (n_embd)) vary: \n",
    "\n",
    "            n_heads \n",
    "            \n",
    "            h_size\n",
    "\n",
    "            seq_len  (seq length affect number of operations for fix head size and nheads, as it increased the projections dimensions, i.e. sizes of K, V, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_system_metrics(username, project):\n",
    "\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(f\"{username}/{project}\")\n",
    "    system_metrics = defaultdict(dict) \n",
    "    \n",
    "    for run in runs:\n",
    "        if run.state =='finished':            \n",
    "            system_metrics[run.name][run.id] = run.history(stream='events') #run.history() is a pandas data frame \n",
    "    \n",
    "    return system_metrics\n",
    "\n",
    "sm = collect_system_metrics(\"m-motta\" , 'profile-attention-nano-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'-n_head'+str(n_head)+'-h_size'+str(n_embd)+'-seq_len'+str(block_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About logged runtimes:\n",
    "\n",
    "there is a difference between the runtime from .history() and .history(stream='events). Firstly, because events are restricted to the GPU, but probably also because the system is checked at specific intervals/checked once again after iterations are finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params flash-n_iters400-n_head6-h_size384-seq_len256\n",
      "id unt2z7wo\n",
      ".iloc[-1] 65.89632\n",
      "\n",
      "params slow-n_iters400-n_head6-h_size384-seq_len256\n",
      "id rnnz8csp\n",
      ".iloc[-1] 77.098952\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'flash-n_iters400-n_head6-h_size384-seq_len256': 65.89632,\n",
       " 'slow-n_iters400-n_head6-h_size384-seq_len256': 77.098952}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_average_runtime(system_metrics):\n",
    "    \n",
    "    runtimes = {}\n",
    "    for params in system_metrics.keys():\n",
    "        print('params',params)\n",
    "        runtimes[params] = 0\n",
    "        count = 0\n",
    "        for id in system_metrics[params].keys():\n",
    "            print('id',id)\n",
    "            print('.iloc[-1]',system_metrics[params][id]._runtime.iloc[-1])\n",
    "            runtimes[params]+= system_metrics[params][id]._runtime.iloc[-1]\n",
    "            count += 1\n",
    "            print('')\n",
    "        runtimes[params] = runtimes[params]/count\n",
    "    \n",
    "    return runtimes    \n",
    "\n",
    "compute_average_runtime(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_system_metrics(username, project):\n",
    "\n",
    "    #this is appending all the runs, I don't think I'll need this\n",
    "\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(f\"{username}/{project}\")\n",
    "    system_metrics = {'flash-attention': [], 'slow-attention': []}\n",
    "    for run in runs:\n",
    "        system_metrics[run.name].append(run.history(stream='events')) #run.history() is a pandas data frame \n",
    "\n",
    "    for key, group in system_metrics.items():\n",
    "        if group:\n",
    "            system_metrics[key] = pd.concat(group, axis=0, join='outer', ignore_index=True)\n",
    "    \n",
    "    return system_metrics\n",
    "\n",
    "#system_metrics = aggregate_system_metrics(\"m-motta\" , 'profile-attention-nano-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_metrics(system_metrics, list_of_matches):\n",
    "    #selects specific metris (columns) from the .history() dataframe, based on string matches\n",
    "    pattern = '|'.join(list_of_matches)\n",
    "\n",
    "    def split_select(s):\n",
    "        return s.split('system.')[1]\n",
    "\n",
    "    system_metrics = {\n",
    "        key: df.filter(regex=pattern, axis=1).rename(columns=split_select)\n",
    "        for key, df in system_metrics.items()\n",
    "    }\n",
    "\n",
    "    return system_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_metrics = aggregate_system_metrics(\"m-motta\" , 'profile-attention-nano-gpt')\n",
    "system_metrics = filter_metrics(system_metrics, ['gpu', 'disk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpu.0.powerPercent</th>\n",
       "      <th>gpu.0.powerWatts</th>\n",
       "      <th>disk.out</th>\n",
       "      <th>disk.\\.usageGB</th>\n",
       "      <th>gpu.0.temp</th>\n",
       "      <th>gpu.0.memory</th>\n",
       "      <th>gpu.0.gpu</th>\n",
       "      <th>gpu.0.memoryAllocatedBytes</th>\n",
       "      <th>disk.\\.usagePercent</th>\n",
       "      <th>disk.in</th>\n",
       "      <th>gpu.0.memoryAllocated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.94</td>\n",
       "      <td>8.02</td>\n",
       "      <td>3.82</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.60</td>\n",
       "      <td>13.93</td>\n",
       "      <td>7.93</td>\n",
       "      <td>8.574687e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.16</td>\n",
       "      <td>10.33</td>\n",
       "      <td>10.62</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.93</td>\n",
       "      <td>3.73</td>\n",
       "      <td>11.93</td>\n",
       "      <td>8.721968e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.33</td>\n",
       "      <td>6.29</td>\n",
       "      <td>16.45</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.20</td>\n",
       "      <td>6.87</td>\n",
       "      <td>16.60</td>\n",
       "      <td>8.805635e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.51</td>\n",
       "      <td>10.52</td>\n",
       "      <td>24.49</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.47</td>\n",
       "      <td>7.87</td>\n",
       "      <td>14.40</td>\n",
       "      <td>8.823680e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.70</td>\n",
       "      <td>9.69</td>\n",
       "      <td>36.57</td>\n",
       "      <td>174.89</td>\n",
       "      <td>47.40</td>\n",
       "      <td>6.27</td>\n",
       "      <td>17.00</td>\n",
       "      <td>9.035754e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gpu.0.powerPercent  gpu.0.powerWatts  disk.out  disk.\\.usageGB  gpu.0.temp  \\\n",
       "0                9.94              8.02      3.82          174.91       47.60   \n",
       "1               12.16             10.33     10.62          174.91       47.93   \n",
       "2                8.33              6.29     16.45          174.91       47.20   \n",
       "3               12.51             10.52     24.49          174.91       47.47   \n",
       "4               11.70              9.69     36.57          174.89       47.40   \n",
       "\n",
       "   gpu.0.memory  gpu.0.gpu  gpu.0.memoryAllocatedBytes  disk.\\.usagePercent  \\\n",
       "0         13.93       7.93                8.574687e+08                 20.3   \n",
       "1          3.73      11.93                8.721968e+08                 20.3   \n",
       "2          6.87      16.60                8.805635e+08                 20.3   \n",
       "3          7.87      14.40                8.823680e+08                 20.3   \n",
       "4          6.27      17.00                9.035754e+08                 20.3   \n",
       "\n",
       "   disk.in  gpu.0.memoryAllocated  \n",
       "0     0.00                   9.99  \n",
       "1     0.00                  10.16  \n",
       "2     0.00                  10.26  \n",
       "3     0.00                  10.28  \n",
       "4     0.01                  10.52  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_metrics['flash-attention'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.gpu.0.powerPercent</th>\n",
       "      <th>system.gpu.0.powerWatts</th>\n",
       "      <th>system.disk.out</th>\n",
       "      <th>system.disk.\\.usageGB</th>\n",
       "      <th>system.gpu.0.temp</th>\n",
       "      <th>system.gpu.0.memory</th>\n",
       "      <th>system.gpu.0.gpu</th>\n",
       "      <th>system.gpu.0.memoryAllocatedBytes</th>\n",
       "      <th>system.disk.\\.usagePercent</th>\n",
       "      <th>system.disk.in</th>\n",
       "      <th>system.gpu.0.memoryAllocated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.94</td>\n",
       "      <td>8.02</td>\n",
       "      <td>3.82</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.60</td>\n",
       "      <td>13.93</td>\n",
       "      <td>7.93</td>\n",
       "      <td>8.574687e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.16</td>\n",
       "      <td>10.33</td>\n",
       "      <td>10.62</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.93</td>\n",
       "      <td>3.73</td>\n",
       "      <td>11.93</td>\n",
       "      <td>8.721968e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.33</td>\n",
       "      <td>6.29</td>\n",
       "      <td>16.45</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.20</td>\n",
       "      <td>6.87</td>\n",
       "      <td>16.60</td>\n",
       "      <td>8.805635e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.51</td>\n",
       "      <td>10.52</td>\n",
       "      <td>24.49</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.47</td>\n",
       "      <td>7.87</td>\n",
       "      <td>14.40</td>\n",
       "      <td>8.823680e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.70</td>\n",
       "      <td>9.69</td>\n",
       "      <td>36.57</td>\n",
       "      <td>174.89</td>\n",
       "      <td>47.40</td>\n",
       "      <td>6.27</td>\n",
       "      <td>17.00</td>\n",
       "      <td>9.035754e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   system.gpu.0.powerPercent  system.gpu.0.powerWatts  system.disk.out  \\\n",
       "0                       9.94                     8.02             3.82   \n",
       "1                      12.16                    10.33            10.62   \n",
       "2                       8.33                     6.29            16.45   \n",
       "3                      12.51                    10.52            24.49   \n",
       "4                      11.70                     9.69            36.57   \n",
       "\n",
       "   system.disk.\\.usageGB  system.gpu.0.temp  system.gpu.0.memory  \\\n",
       "0                 174.91              47.60                13.93   \n",
       "1                 174.91              47.93                 3.73   \n",
       "2                 174.91              47.20                 6.87   \n",
       "3                 174.91              47.47                 7.87   \n",
       "4                 174.89              47.40                 6.27   \n",
       "\n",
       "   system.gpu.0.gpu  system.gpu.0.memoryAllocatedBytes  \\\n",
       "0              7.93                       8.574687e+08   \n",
       "1             11.93                       8.721968e+08   \n",
       "2             16.60                       8.805635e+08   \n",
       "3             14.40                       8.823680e+08   \n",
       "4             17.00                       9.035754e+08   \n",
       "\n",
       "   system.disk.\\.usagePercent  system.disk.in  system.gpu.0.memoryAllocated  \n",
       "0                        20.3            0.00                          9.99  \n",
       "1                        20.3            0.00                         10.16  \n",
       "2                        20.3            0.00                         10.26  \n",
       "3                        20.3            0.00                         10.28  \n",
       "4                        20.3            0.01                         10.52  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "system_metrics['flash-attention'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpu.0.powerPercent',\n",
       " 'gpu.0.powerWatts',\n",
       " 'disk.out',\n",
       " 'disk.\\\\.usageGB',\n",
       " 'gpu.0.temp',\n",
       " 'gpu.0.memory',\n",
       " 'gpu.0.gpu',\n",
       " 'gpu.0.memoryAllocatedBytes',\n",
       " 'disk.\\\\.usagePercent',\n",
       " 'disk.in',\n",
       " 'gpu.0.memoryAllocated']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = ['gpu', 'disk']\n",
    "metrics = system_metrics['flash-attention'].columns\n",
    "metrics = [m.split('system.')[1] for m in metrics if any([p in m for p in params])]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['schemaVersion', 'deviceProperties', 'distributedInfo', 'with_flops', 'with_modules', 'with_stack', 'traceEvents', 'traceName']\n",
    "#only deviceProperties and traceEvents contain relevant information\n",
    "data = []\n",
    "for run in glob.glob(f\"{out_dir}/**/*.pt.trace.json\", recursive=True):\n",
    "  #  print('\\n',run)\n",
    "    with open(run) as jsonFile:\n",
    "        data.append(json.load(jsonFile))\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notes from paper:\n",
    "\n",
    "All models are trained with the same hyperparameters for 400K steps.\n",
    "\n",
    "We run all implementations with mixed-precision training (PyTorch AMP).\n",
    "\n",
    "Speedup also changes when we increase the head dimension. Each block\n",
    "requires more memory, so we need to use smaller block sizes to fit into SRAM. Figure 6 shows speedup with\n",
    "head dimension 128 on an A100 (batch size 16, 12 heads). We see less speedup overall—but we can still see\n",
    "significant speedup (up to 3×) with a causal mask, where half the blocks are masked out.\n",
    "                     \n",
    "We confirm that the memory footprint\n",
    "of FlashAttention scales linearly with seq. length and is up to 3× faster than standard attention for\n",
    "common seq. lengths (up to 2K). We confirm that runtime of block-sparse FlashAttention scales linearly\n",
    "in seq. length and is faster than all existing approximate attention baselines.\n",
    "                     \n",
    "We train the model on 8×A100-80GB GPUs. Each training run takes between 16 and 19 minutes, and we\n",
    "average the results of 10 runs.\n",
    "                     \n",
    "attension head, seq length and block size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
