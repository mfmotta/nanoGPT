{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from config.train_shakespeare_char import *\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mm-motta\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/nanoGPT/wandb/run-20231012_113736-z25qq9cp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/m-motta/profile-attention-nano-gpt/runs/z25qq9cp' target=\"_blank\">flash-n_iters400-n_head6-h_size384-seq_len256</a></strong> to <a href='https://wandb.ai/m-motta/profile-attention-nano-gpt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/m-motta/profile-attention-nano-gpt' target=\"_blank\">https://wandb.ai/m-motta/profile-attention-nano-gpt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/m-motta/profile-attention-nano-gpt/runs/z25qq9cp' target=\"_blank\">https://wandb.ai/m-motta/profile-attention-nano-gpt/runs/z25qq9cp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'backend': 'nccl', 'device': 'cuda', 'dtype': 'bfloat16', 'compile': True}\n",
    "wandb.init(project=wandb_project, name=wandb_run_name, config=config, sync_tensorboard=True)\n",
    "wandb.login()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run experiments:\n",
    "\n",
    "vary:\n",
    "\n",
    "n_iters  - to check if profiling changes with more or less iterations --it should not\n",
    "\n",
    "        for (n_heads*h_size=const) vary: \n",
    "\n",
    "            n_heads \n",
    "            \n",
    "            h_size\n",
    "\n",
    "            seq_len  (seq length affect number of operations for fix head size and nheads, as it increased the projections dimensions, i.e. sizes of K, V, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_system_metrics(username, project):\n",
    "\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(f\"{username}/{project}\")\n",
    "    system_metrics = defaultdict(dict) \n",
    "    \n",
    "    for run in runs:\n",
    "        if run.state =='finished':            \n",
    "            system_metrics[run.name][run.id] = run.history(stream='events') #run.history() is a pandas data frame \n",
    "    \n",
    "    return system_metrics\n",
    "\n",
    "sm = collect_system_metrics(\"m-motta\" , 'profile-attention-nano-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'-n_head'+str(n_head)+'-h_size'+str(n_embd)+'-seq_len'+str(block_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About logged runtimes:\n",
    "\n",
    "there is a difference between the runtime from .history() and .history(stream='events). Firstly, because events are restricted to the GPU, but probably also because the system is checked at specific intervals/checked once again after iterations are finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params flash-n_iters400-n_head6-h_size384-seq_len256\n",
      "id unt2z7wo\n",
      ".iloc[-1] 65.89632\n",
      "\n",
      "params slow-n_iters400-n_head6-h_size384-seq_len256\n",
      "id rnnz8csp\n",
      ".iloc[-1] 77.098952\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'flash-n_iters400-n_head6-h_size384-seq_len256': 65.89632,\n",
       " 'slow-n_iters400-n_head6-h_size384-seq_len256': 77.098952}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_average_runtime(system_metrics):\n",
    "    \n",
    "    runtimes = {}\n",
    "    for params in system_metrics.keys():\n",
    "        print('params',params)\n",
    "        runtimes[params] = 0\n",
    "        count = 0\n",
    "        for id in system_metrics[params].keys():\n",
    "            print('id',id)\n",
    "            print('.iloc[-1]',system_metrics[params][id]._runtime.iloc[-1])\n",
    "            runtimes[params]+= system_metrics[params][id]._runtime.iloc[-1]\n",
    "            count += 1\n",
    "            print('')\n",
    "        runtimes[params] = runtimes[params]/count\n",
    "    \n",
    "    return runtimes    \n",
    "\n",
    "compute_average_runtime(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_system_metrics(username, project):\n",
    "\n",
    "    #this is appending all the runs, I don't think I'll need this\n",
    "\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(f\"{username}/{project}\")\n",
    "    system_metrics = {'flash-attention': [], 'slow-attention': []}\n",
    "    for run in runs:\n",
    "        system_metrics[run.name].append(run.history(stream='events')) #run.history() is a pandas data frame \n",
    "\n",
    "    for key, group in system_metrics.items():\n",
    "        if group:\n",
    "            system_metrics[key] = pd.concat(group, axis=0, join='outer', ignore_index=True)\n",
    "    \n",
    "    return system_metrics\n",
    "\n",
    "#system_metrics = aggregate_system_metrics(\"m-motta\" , 'profile-attention-nano-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_metrics(system_metrics, list_of_matches):\n",
    "    #selects specific metris (columns) from the .history() dataframe, based on string matches\n",
    "    pattern = '|'.join(list_of_matches)\n",
    "\n",
    "    def split_select(s):\n",
    "        return s.split('system.')[1]\n",
    "\n",
    "    system_metrics = {\n",
    "        key: df.filter(regex=pattern, axis=1).rename(columns=split_select)\n",
    "        for key, df in system_metrics.items()\n",
    "    }\n",
    "\n",
    "    return system_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_metrics = aggregate_system_metrics(\"m-motta\" , 'profile-attention-nano-gpt')\n",
    "system_metrics = filter_metrics(system_metrics, ['gpu', 'disk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpu.0.powerPercent</th>\n",
       "      <th>gpu.0.powerWatts</th>\n",
       "      <th>disk.out</th>\n",
       "      <th>disk.\\.usageGB</th>\n",
       "      <th>gpu.0.temp</th>\n",
       "      <th>gpu.0.memory</th>\n",
       "      <th>gpu.0.gpu</th>\n",
       "      <th>gpu.0.memoryAllocatedBytes</th>\n",
       "      <th>disk.\\.usagePercent</th>\n",
       "      <th>disk.in</th>\n",
       "      <th>gpu.0.memoryAllocated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.94</td>\n",
       "      <td>8.02</td>\n",
       "      <td>3.82</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.60</td>\n",
       "      <td>13.93</td>\n",
       "      <td>7.93</td>\n",
       "      <td>8.574687e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.16</td>\n",
       "      <td>10.33</td>\n",
       "      <td>10.62</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.93</td>\n",
       "      <td>3.73</td>\n",
       "      <td>11.93</td>\n",
       "      <td>8.721968e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.33</td>\n",
       "      <td>6.29</td>\n",
       "      <td>16.45</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.20</td>\n",
       "      <td>6.87</td>\n",
       "      <td>16.60</td>\n",
       "      <td>8.805635e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.51</td>\n",
       "      <td>10.52</td>\n",
       "      <td>24.49</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.47</td>\n",
       "      <td>7.87</td>\n",
       "      <td>14.40</td>\n",
       "      <td>8.823680e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.70</td>\n",
       "      <td>9.69</td>\n",
       "      <td>36.57</td>\n",
       "      <td>174.89</td>\n",
       "      <td>47.40</td>\n",
       "      <td>6.27</td>\n",
       "      <td>17.00</td>\n",
       "      <td>9.035754e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gpu.0.powerPercent  gpu.0.powerWatts  disk.out  disk.\\.usageGB  gpu.0.temp  \\\n",
       "0                9.94              8.02      3.82          174.91       47.60   \n",
       "1               12.16             10.33     10.62          174.91       47.93   \n",
       "2                8.33              6.29     16.45          174.91       47.20   \n",
       "3               12.51             10.52     24.49          174.91       47.47   \n",
       "4               11.70              9.69     36.57          174.89       47.40   \n",
       "\n",
       "   gpu.0.memory  gpu.0.gpu  gpu.0.memoryAllocatedBytes  disk.\\.usagePercent  \\\n",
       "0         13.93       7.93                8.574687e+08                 20.3   \n",
       "1          3.73      11.93                8.721968e+08                 20.3   \n",
       "2          6.87      16.60                8.805635e+08                 20.3   \n",
       "3          7.87      14.40                8.823680e+08                 20.3   \n",
       "4          6.27      17.00                9.035754e+08                 20.3   \n",
       "\n",
       "   disk.in  gpu.0.memoryAllocated  \n",
       "0     0.00                   9.99  \n",
       "1     0.00                  10.16  \n",
       "2     0.00                  10.26  \n",
       "3     0.00                  10.28  \n",
       "4     0.01                  10.52  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_metrics['flash-attention'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>system.gpu.0.powerPercent</th>\n",
       "      <th>system.gpu.0.powerWatts</th>\n",
       "      <th>system.disk.out</th>\n",
       "      <th>system.disk.\\.usageGB</th>\n",
       "      <th>system.gpu.0.temp</th>\n",
       "      <th>system.gpu.0.memory</th>\n",
       "      <th>system.gpu.0.gpu</th>\n",
       "      <th>system.gpu.0.memoryAllocatedBytes</th>\n",
       "      <th>system.disk.\\.usagePercent</th>\n",
       "      <th>system.disk.in</th>\n",
       "      <th>system.gpu.0.memoryAllocated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.94</td>\n",
       "      <td>8.02</td>\n",
       "      <td>3.82</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.60</td>\n",
       "      <td>13.93</td>\n",
       "      <td>7.93</td>\n",
       "      <td>8.574687e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.16</td>\n",
       "      <td>10.33</td>\n",
       "      <td>10.62</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.93</td>\n",
       "      <td>3.73</td>\n",
       "      <td>11.93</td>\n",
       "      <td>8.721968e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.33</td>\n",
       "      <td>6.29</td>\n",
       "      <td>16.45</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.20</td>\n",
       "      <td>6.87</td>\n",
       "      <td>16.60</td>\n",
       "      <td>8.805635e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.51</td>\n",
       "      <td>10.52</td>\n",
       "      <td>24.49</td>\n",
       "      <td>174.91</td>\n",
       "      <td>47.47</td>\n",
       "      <td>7.87</td>\n",
       "      <td>14.40</td>\n",
       "      <td>8.823680e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.70</td>\n",
       "      <td>9.69</td>\n",
       "      <td>36.57</td>\n",
       "      <td>174.89</td>\n",
       "      <td>47.40</td>\n",
       "      <td>6.27</td>\n",
       "      <td>17.00</td>\n",
       "      <td>9.035754e+08</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   system.gpu.0.powerPercent  system.gpu.0.powerWatts  system.disk.out  \\\n",
       "0                       9.94                     8.02             3.82   \n",
       "1                      12.16                    10.33            10.62   \n",
       "2                       8.33                     6.29            16.45   \n",
       "3                      12.51                    10.52            24.49   \n",
       "4                      11.70                     9.69            36.57   \n",
       "\n",
       "   system.disk.\\.usageGB  system.gpu.0.temp  system.gpu.0.memory  \\\n",
       "0                 174.91              47.60                13.93   \n",
       "1                 174.91              47.93                 3.73   \n",
       "2                 174.91              47.20                 6.87   \n",
       "3                 174.91              47.47                 7.87   \n",
       "4                 174.89              47.40                 6.27   \n",
       "\n",
       "   system.gpu.0.gpu  system.gpu.0.memoryAllocatedBytes  \\\n",
       "0              7.93                       8.574687e+08   \n",
       "1             11.93                       8.721968e+08   \n",
       "2             16.60                       8.805635e+08   \n",
       "3             14.40                       8.823680e+08   \n",
       "4             17.00                       9.035754e+08   \n",
       "\n",
       "   system.disk.\\.usagePercent  system.disk.in  system.gpu.0.memoryAllocated  \n",
       "0                        20.3            0.00                          9.99  \n",
       "1                        20.3            0.00                         10.16  \n",
       "2                        20.3            0.00                         10.26  \n",
       "3                        20.3            0.00                         10.28  \n",
       "4                        20.3            0.01                         10.52  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "system_metrics['flash-attention'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpu.0.powerPercent',\n",
       " 'gpu.0.powerWatts',\n",
       " 'disk.out',\n",
       " 'disk.\\\\.usageGB',\n",
       " 'gpu.0.temp',\n",
       " 'gpu.0.memory',\n",
       " 'gpu.0.gpu',\n",
       " 'gpu.0.memoryAllocatedBytes',\n",
       " 'disk.\\\\.usagePercent',\n",
       " 'disk.in',\n",
       " 'gpu.0.memoryAllocated']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = ['gpu', 'disk']\n",
    "metrics = system_metrics['flash-attention'].columns\n",
    "metrics = [m.split('system.')[1] for m in metrics if any([p in m for p in params])]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#['schemaVersion', 'deviceProperties', 'distributedInfo', 'with_flops', 'with_modules', 'with_stack', 'traceEvents', 'traceName']\n",
    "#only deviceProperties and traceEvents contain relevant information\n",
    "data = []\n",
    "for run in glob.glob(f\"{out_dir}/**/*.pt.trace.json\", recursive=True):\n",
    "  #  print('\\n',run)\n",
    "    with open(run) as jsonFile:\n",
    "        data.append(json.load(jsonFile))\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notes from paper:\n",
    "\n",
    "All models are trained with the same hyperparameters for 400K steps.\n",
    "\n",
    "We run all implementations with mixed-precision training (PyTorch AMP).\n",
    "\n",
    "Speedup also changes when we increase the head dimension. Each block\n",
    "requires more memory, so we need to use smaller block sizes to fit into SRAM. Figure 6 shows speedup with\n",
    "head dimension 128 on an A100 (batch size 16, 12 heads). We see less speedup overall—but we can still see\n",
    "significant speedup (up to 3×) with a causal mask, where half the blocks are masked out.\n",
    "                     \n",
    "We confirm that the memory footprint\n",
    "of FlashAttention scales linearly with seq. length and is up to 3× faster than standard attention for\n",
    "common seq. lengths (up to 2K). We confirm that runtime of block-sparse FlashAttention scales linearly\n",
    "in seq. length and is faster than all existing approximate attention baselines.\n",
    "                     \n",
    "We train the model on 8×A100-80GB GPUs. Each training run takes between 16 and 19 minutes, and we\n",
    "average the results of 10 runs.\n",
    "                     \n",
    "attension head, seq length and block size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
