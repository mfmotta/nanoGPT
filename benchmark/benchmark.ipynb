{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import pathlib\n",
    "\n",
    "from utils import *\n",
    "\n",
    "sys.path.insert(1, '../') #ugly hack\n",
    "import config.train_shakespeare_char as params\n",
    "from train_torch_profiler import wandb_config, main as train\n",
    "\n",
    "current_dir =  pathlib.Path().resolve()\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] =  os.path.join(current_dir)\n",
    "\n",
    "warnings.filterwarnings(action='once')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling with PyTorch\n",
    "\n",
    "We will first perform a sanity check and see whether profiling with a different number of iterations leads to significantly different results.\n",
    "\n",
    "We keep all parameters fixed, whily varying the number of iterations and the type of attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params = dict(n_layer = params.n_layer, \n",
    "                    n_head = params.n_head, \n",
    "                    n_embd = params.n_embd, \n",
    "                    block_size = params.block_size,\n",
    "                    bias = params.bias, \n",
    "                    dropout = params.dropout) \n",
    "\n",
    "varying_params = dict(max_iters = [400, 1000], #less than 400 iterations didn't lead to wandb system metrics\n",
    "                      flash = [True, False])\n",
    "\n",
    "profiling_params = params.profiler_schedule_args\n",
    "print(' profiling_params', profiling_params)\n",
    "\n",
    "experiment_params = combine_all_keys_and_values(varying_params)\n",
    "print('\\n experiment_params',experiment_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sanity check\n",
    "#train with experiment_params\n",
    "for exp_params in experiment_params:\n",
    "    print('\\n \\n train with', exp_params)\n",
    "    with set_params(params, exp_params): #check if reinit=True in wandb is better\n",
    "        random_port = 1024 + random.randint(1,1000)\n",
    "        setattr(params, 'random_port', random_port)\n",
    "        print(params.random_port)\n",
    "        train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For single runs with 400 and 1000 iterations respectively, we see that mean kernel occupancy and duration (time of kernel activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " kernel: triton__0d1d2d3d4d5d6d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_occupancy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flash</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flash-block_size256-n_head6-n_embd384-max_iters400skip_first5-wait5-warmup5-active3-repeat1</th>\n",
       "      <td>174</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flash-block_size256-n_head6-n_embd384-max_iters1000skip_first5-wait5-warmup5-active3-repeat1</th>\n",
       "      <td>184</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_duration  \\\n",
       "flash                                                               \n",
       "flash-block_size256-n_head6-n_embd384-max_iters...            174   \n",
       "flash-block_size256-n_head6-n_embd384-max_iters...            184   \n",
       "\n",
       "                                                    mean_occupancy  \n",
       "flash                                                               \n",
       "flash-block_size256-n_head6-n_embd384-max_iters...            83.0  \n",
       "flash-block_size256-n_head6-n_embd384-max_iters...            83.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_occupancy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slow</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>slow-block_size256-n_head6-n_embd384-max_iters1000skip_first5-wait5-warmup5-active3-repeat1</th>\n",
       "      <td>882</td>\n",
       "      <td>99.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slow-block_size256-n_head6-n_embd384-max_iters400skip_first5-wait5-warmup5-active3-repeat1</th>\n",
       "      <td>904</td>\n",
       "      <td>99.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_duration  \\\n",
       "slow                                                                \n",
       "slow-block_size256-n_head6-n_embd384-max_iters1...            882   \n",
       "slow-block_size256-n_head6-n_embd384-max_iters4...            904   \n",
       "\n",
       "                                                    mean_occupancy  \n",
       "slow                                                                \n",
       "slow-block_size256-n_head6-n_embd384-max_iters1...           99.16  \n",
       "slow-block_size256-n_head6-n_embd384-max_iters4...           99.19  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " kernel: ampere_bf16_s1688gemm_bf16_128x128_ldg8_f2f_tn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_occupancy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flash</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>flash-block_size256-n_head6-n_embd384-max_iters400skip_first5-wait5-warmup5-active3-repeat1</th>\n",
       "      <td>528</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flash-block_size256-n_head6-n_embd384-max_iters1000skip_first5-wait5-warmup5-active3-repeat1</th>\n",
       "      <td>507</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_duration  \\\n",
       "flash                                                               \n",
       "flash-block_size256-n_head6-n_embd384-max_iters...            528   \n",
       "flash-block_size256-n_head6-n_embd384-max_iters...            507   \n",
       "\n",
       "                                                    mean_occupancy  \n",
       "flash                                                               \n",
       "flash-block_size256-n_head6-n_embd384-max_iters...            17.0  \n",
       "flash-block_size256-n_head6-n_embd384-max_iters...            17.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_occupancy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slow</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>slow-block_size256-n_head6-n_embd384-max_iters1000skip_first5-wait5-warmup5-active3-repeat1</th>\n",
       "      <td>534</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slow-block_size256-n_head6-n_embd384-max_iters400skip_first5-wait5-warmup5-active3-repeat1</th>\n",
       "      <td>571</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_duration  \\\n",
       "slow                                                                \n",
       "slow-block_size256-n_head6-n_embd384-max_iters1...            534   \n",
       "slow-block_size256-n_head6-n_embd384-max_iters4...            571   \n",
       "\n",
       "                                                    mean_occupancy  \n",
       "slow                                                                \n",
       "slow-block_size256-n_head6-n_embd384-max_iters1...            17.0  \n",
       "slow-block_size256-n_head6-n_embd384-max_iters4...            17.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for kernel in ['triton__0d1d2d3d4d5d6d', 'ampere_bf16_s1688gemm_bf16_128x128_ldg8_f2f_tn']:\n",
    "    print('\\n kernel:', kernel)\n",
    "    for attention in ['flash', 'slow']:\n",
    "        display(compare_runs(params.out_dir, attention, kernel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_duration</th>\n",
       "      <th>mean_occupancy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>slow-block_size256-n_head6-n_embd384-max_iters1000skip_first5-wait5-warmup5-active3-repeat1</th>\n",
       "      <td>882</td>\n",
       "      <td>99.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slow-block_size256-n_head6-n_embd384-max_iters400skip_first5-wait5-warmup5-active3-repeat1</th>\n",
       "      <td>904</td>\n",
       "      <td>99.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    mean_duration  \\\n",
       "slow-block_size256-n_head6-n_embd384-max_iters1...            882   \n",
       "slow-block_size256-n_head6-n_embd384-max_iters4...            904   \n",
       "\n",
       "                                                    mean_occupancy  \n",
       "slow-block_size256-n_head6-n_embd384-max_iters1...           99.16  \n",
       "slow-block_size256-n_head6-n_embd384-max_iters4...           99.19  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_runs(params.out_dir, 'slow', 'triton__0d1d2d3d4d5d6d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments:\n",
    "\n",
    "vary: \n",
    "\n",
    "(n_heads*h_size = embedding dimensionality (n_embd)) \n",
    "\n",
    "n_heads \n",
    "            \n",
    "h_size\n",
    "\n",
    "seq_len  \n",
    "\n",
    "(number of parameters in scaling_laws.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_system_metrics(username, project):#\n",
    "\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(f\"{username}/{project}\")\n",
    "    system_metrics = defaultdict(dict) \n",
    "    \n",
    "    for run in runs:\n",
    "        if run.state =='finished':         \n",
    "            system_metrics[run.name][run.id] = run.history(stream='events') #run.history() is a pandas data frame \n",
    "    \n",
    "    return system_metrics\n",
    "\n",
    "sm = wandb_system_metrics(\"m-motta\" , 'profile-attention-nano-gpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About logged runtimes:\n",
    "\n",
    "there is a difference between the runtime from .history() and .history(stream='events). Firstly, because events are restricted to the GPU, but probably also because the system is checked at specific intervals/checked once again after iterations are finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_runtime(system_metrics):\n",
    "    \n",
    "    runtimes = {}\n",
    "    for params in system_metrics.keys():\n",
    "        print('params',params)\n",
    "        runtimes[params] = 0\n",
    "        count = 0\n",
    "        for id in system_metrics[params].keys():\n",
    "            print('id',id)\n",
    "            print('.iloc[-1]',system_metrics[params][id]._runtime.iloc[-1])\n",
    "            runtimes[params]+= system_metrics[params][id]._runtime.iloc[-1]\n",
    "            count += 1\n",
    "            print('')\n",
    "        runtimes[params] = runtimes[params]/count\n",
    "    \n",
    "    return runtimes    \n",
    "\n",
    "compute_average_runtime(sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_wandb_system_metrics(username, project):\n",
    "\n",
    "    #this is appending all the runs, I don't think I'll need this\n",
    "\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(f\"{username}/{project}\")\n",
    "    system_metrics = {'flash-attention': [], 'slow-attention': []}\n",
    "    for run in runs:\n",
    "        system_metrics[run.name].append(run.history(stream='events')) #run.history() is a pandas data frame \n",
    "\n",
    "    for key, group in system_metrics.items():\n",
    "        if group:\n",
    "            system_metrics[key] = pd.concat(group, axis=0, join='outer', ignore_index=True)\n",
    "    \n",
    "    return system_metrics\n",
    "\n",
    "#system_metrics = aggregate_wandb_system_metrics(\"m-motta\" , 'profile-attention-nano-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_metrics(system_metrics, list_of_matches):\n",
    "    #selects specific metris (columns) from the .history() dataframe, based on string matches\n",
    "    pattern = '|'.join(list_of_matches)\n",
    "\n",
    "    def split_select(s):\n",
    "        return s.split('system.')[1]\n",
    "\n",
    "    system_metrics = {\n",
    "        key: df.filter(regex=pattern, axis=1).rename(columns=split_select)\n",
    "        for key, df in system_metrics.items()\n",
    "    }\n",
    "\n",
    "    return system_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_metrics = aggregate_wandb_system_metrics(\"m-motta\" , 'profile-attention-nano-gpt')\n",
    "system_metrics = filter_metrics(system_metrics, ['gpu', 'disk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_metrics['flash-attention'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_metrics['flash-attention'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['gpu', 'disk']\n",
    "metrics = system_metrics['flash-attention'].columns\n",
    "metrics = [m.split('system.')[1] for m in metrics if any([p in m for p in params])]\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Notes from paper:\n",
    "\n",
    "All models are trained with the same hyperparameters for 400K steps.\n",
    "\n",
    "We run all implementations with mixed-precision training (PyTorch AMP).\n",
    "\n",
    "Speedup also changes when we increase the head dimension. Each block\n",
    "requires more memory, so we need to use smaller block sizes to fit into SRAM. Figure 6 shows speedup with\n",
    "head dimension 128 on an A100 (batch size 16, 12 heads). We see less speedup overall—but we can still see\n",
    "significant speedup (up to 3×) with a causal mask, where half the blocks are masked out.\n",
    "                     \n",
    "We confirm that the memory footprint\n",
    "of FlashAttention scales linearly with seq. length and is up to 3× faster than standard attention for\n",
    "common seq. lengths (up to 2K). We confirm that runtime of block-sparse FlashAttention scales linearly\n",
    "in seq. length and is faster than all existing approximate attention baselines.\n",
    "                     \n",
    "We train the model on 8×A100-80GB GPUs. Each training run takes between 16 and 19 minutes, and we\n",
    "average the results of 10 runs.\n",
    "                     \n",
    "attension head, seq length and block size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO further refactor train.py?  https://github.com/pytorch/examples/blob/main/imagenet/main.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
